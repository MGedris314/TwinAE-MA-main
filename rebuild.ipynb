{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e538136",
   "metadata": {},
   "source": [
    "# Sanity\n",
    "Okay this is mostly to help me keep my sanity.  I'm grabbing what I think is the most important parts of the helix notebook and trying to get a clean environment to build out what I need for this week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d761c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from AutoEncoders import GRAEAnchor\n",
    "import pandas as pd\n",
    "from data_creation import generate_line_and_helix, generate_line_and_helix_with_noise\n",
    "from helpers import *\n",
    "from mashspud import MASH, SPUD\n",
    "from cluster_help import *\n",
    "\n",
    "def mod_anchors(anchors, removal):\n",
    "    sort_anchors=np.sort(anchors)\n",
    "    sort_remove=list(removal)\n",
    "    for x in range(len(sort_anchors)):\n",
    "        for y in range(len(sort_remove)):\n",
    "            if sort_anchors[x]>=sort_remove[y]:\n",
    "                sort_anchors[x]=sort_anchors[x]-1\n",
    "    return(np.sort(sort_anchors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "line, helix = generate_line_and_helix(200)\n",
    "line_noisy, helix_noisy,noise_points = generate_line_and_helix_with_noise(200, noise_percentage=0.10, noise_scale=0.35)\n",
    "\n",
    "training=helix\n",
    "training_line=line\n",
    "testing=helix_noisy\n",
    "testing_line=line_noisy\n",
    "anchors = create_anchors(len(helix))[:10]\n",
    "\n",
    "spud_helix = SPUD()\n",
    "spud_helix.fit(training.to_numpy(), training_line.to_numpy(), anchors)\n",
    "spud_helix.plot_emb(labels=None)\n",
    "spud_noisy = SPUD()\n",
    "spud_noisy.fit(testing.to_numpy(), testing_line.to_numpy(), anchors)\n",
    "spud_noisy.plot_emb(labels=None)\n",
    "mash_helix = MASH()\n",
    "mash_helix.fit(training.to_numpy(), training_line.to_numpy(), anchors)\n",
    "mash_helix.plot_emb(labels=None)\n",
    "mash_noisy = MASH()\n",
    "mash_noisy.fit(testing.to_numpy(), testing_line.to_numpy(), anchors)\n",
    "mash_noisy.plot_emb(labels=None)\n",
    "# print(type(mash_helix))\n",
    "\n",
    "fig = plt.figure(figsize=(11, 7))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(line_noisy['x'], line_noisy['y'], label='Line (noisy)', color='tab:cyan')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('Line (noisy)')\n",
    "ax1.legend()\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax2.plot(helix_noisy['x'], helix_noisy['y'], helix_noisy['z'], label='Helix (noisy)', color='tab:purple')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_zlabel('z')\n",
    "ax2.set_title('Helix (noisy)')\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d60e503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the auto encoders.\n",
    "AutoEncA = GRAEAnchor(lam=100, anchor_lam=100, relax=True, n_components = 2)\n",
    "AutoEncA.fit(training.to_numpy(), spud_helix.emb[:len(training)], anchors)\n",
    "AutoEncB = GRAEAnchor(lam=100, anchor_lam=100, relax=True, n_components = 2)\n",
    "AutoEncB.fit(training_line.to_numpy(), spud_helix.emb[len(training_line):], anchors)\n",
    "AutoEncA_m = GRAEAnchor(lam=100, anchor_lam=100, relax=False, n_components = 2)\n",
    "AutoEncA_m.fit(training.to_numpy(), mash_helix.emb[len(training):], anchors)\n",
    "AutoEncB_m = GRAEAnchor(lam=100, anchor_lam=100, relax=False, n_components = 2)\n",
    "AutoEncB_m.fit(training_line.to_numpy(), mash_helix.emb[len(training):], anchors)\n",
    "AutoEnc_snh = GRAEAnchor(lam=100, anchor_lam=100, relax=False, n_components = 2)\n",
    "# Noisy stuff starts here.\n",
    "AutoEnc_snh.fit(testing.to_numpy(), spud_noisy.emb[:len(testing)], anchors)\n",
    "AutoEnc_snl = GRAEAnchor(lam=100, anchor_lam=100, relax=False, n_components = 2)\n",
    "AutoEnc_snl.fit(testing_line.to_numpy(), spud_noisy.emb[len(testing):], anchors)\n",
    "AutoEnc_mnh = GRAEAnchor(lam=100, anchor_lam=100, relax=False, n_components = 2)\n",
    "AutoEnc_mnh.fit(testing.to_numpy(), mash_noisy.emb[:len(testing)], anchors)\n",
    "AutoEnc_mnl = GRAEAnchor(lam=100, anchor_lam=100, relax=False, n_components = 2)\n",
    "AutoEnc_mnl.fit(testing_line.to_numpy(), mash_noisy.emb[:len(testing_line)], anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7abdf6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations and inverse transformations for noisy helix with SPUD and MASH values.\n",
    "spud_helix_encoded=AutoEnc_snh.transform(helix_noisy.values)\n",
    "mash_helix_encoded=AutoEnc_mnh.transform(helix_noisy.values)\n",
    "\n",
    "inverter_spud=AutoEnc_snh.inverse_transform(spud_helix_encoded)\n",
    "inverter_mash=AutoEnc_mnh.inverse_transform(mash_helix_encoded)\n",
    "\n",
    "mash_line_encoded=AutoEnc_mnl.transform(line_noisy.values)\n",
    "inverter_line=AutoEnc_mnl.inverse_transform(mash_line_encoded)\n",
    "\n",
    "spud_line_encoder=AutoEnc_snl.transform(line_noisy.values)\n",
    "spud_line_inverter=AutoEnc_snl.inverse_transform(spud_line_encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
